{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> HW2 Report </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/nirajdalavi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nirajdalavi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nirajdalavi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "python version: 3.12.8\n",
    "beautifulsoup4==4.12.2\n",
    "bs4==0.0.2\n",
    "gensim==4.3.3\n",
    "joblib==1.4.2\n",
    "nltk==3.9.1\n",
    "numpy==1.26.4\n",
    "pandas==2.2.3\n",
    "regex==2024.11.6\n",
    "scikit-learn==1.6.1\n",
    "scipy==1.13.1\n",
    "soupsieve==2.5\n",
    "threadpoolctl==3.5.0\n",
    "torch==2.6.0\n",
    "torchaudio==2.6.0\n",
    "torchvision==0.21.0\n",
    "tqdm==4.67.1\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_frame = pd.read_csv(\"data.tsv\", sep=\"\\t\", on_bad_lines='skip', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this, I have kept the 2 columns review_body and star_rating. Columns that have any null or bad values are dropped. 50000 reviews are picked from each star_rating values. After that, I have created a new column sentiment. The sentiment column has value 1 for positive class, 2 for negative class and 3 for neutral class. I have shuffled the dataset for better results while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/t8b4fmzd1vn4x8ky425rp7l40000gn/T/ipykernel_25098/3038514753.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  balanced_df = pd_frame.groupby(\"star_rating\").apply(lambda x: x.sample(n=50000, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "pd_frame = pd_frame[['review_body', 'star_rating']] \n",
    "pd_frame=pd_frame.dropna(subset=['star_rating','review_body'], how='any')\n",
    "pd_frame['star_rating'] = pd.to_numeric(pd_frame['star_rating'], errors='coerce')\n",
    "\n",
    "balanced_df = pd_frame.groupby(\"star_rating\").apply(lambda x: x.sample(n=50000, random_state=42)).reset_index(drop=True)\n",
    "balanced_df['sentiment'] = balanced_df['star_rating'].apply(\n",
    "    lambda x: 1 if x > 3 else (2 if x <= 2 else 3)\n",
    ")\n",
    "\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have extracted the Word2Vec features from pretrained Google news dataset in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doctor - Hospital + Court = [('judge', 0.6122931838035583)]\n",
      "Similarity between 'happy' and 'satisfied': 0.6437949\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "pre_model = api.load('word2vec-google-news-300')\n",
    "result = pre_model.most_similar(positive=[\"doctor\", \"court\"], negative=[\"hospital\"], topn=1)\n",
    "print(\"Doctor - Hospital + Court =\", result)\n",
    "\n",
    "similarity = pre_model.similarity(\"happy\", \"satisfied\")\n",
    "print(\"Similarity between 'happy' and 'satisfied':\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the Word2Vec features from the self trained model are extracted. I have passed the tokenized review_body along with the parameters mentioned in the question (vector_size=300, window=11, min_count=10,workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doctor - Hospital + Court = [('documenting', 0.4553646147251129)]\n",
      "Similarity between 'happy' and 'satisfied' (Custom Model): 0.9003303\n"
     ]
    }
   ],
   "source": [
    "custom_mod = Word2Vec(sentences=balanced_df['review_body'].apply(word_tokenize), vector_size=300, window=11, min_count=10, workers=1, seed=43)\n",
    "\n",
    "result_custom = custom_mod.wv.most_similar(positive=[\"doctor\", \"court\"], negative=[\"hospital\"], topn=1)\n",
    "print(\"Doctor - Hospital + Court =\", result_custom)\n",
    "\n",
    "similarity_custom = custom_mod.wv.similarity(\"happy\", \"satisfied\")\n",
    "print(\"Similarity between 'happy' and 'satisfied' (Custom Model):\", similarity_custom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion from comparing vectors generated by custom and the pretrained model\n",
    "\n",
    "<h3>Question a</h3>\n",
    "Since the pretrained google news model is trained on a diverse corpus, it encompasses multiple domains. In my example, “Doctor - Hospital + Court”, the model predicts “judge”, which aligns with the fact that courts are linked with judges.<br> Also, the similarity score of 0.6438 between “happy” and “satisfied” indicates a moderate semantic relationship.<br><br>\n",
    "On the other hand, our custom model gives different results for the same example. It predicts “documenting”, which used in the context of legal claims, refunds, policies, or disputes. This explains why “documenting” could be linked with “court” in pretrained model rather than \"judge\". Some reviews may discuss about legal issues.\n",
    "<br>\n",
    "However, the custom model assigns a higher similarity score (0.9003) between “happy” and “satisfied”, indicating that in the context of customer reviews, these words are used more interchangeably.<br><br>\n",
    "Overall, the custom model better captures word associations specific to the Amazon reviews dataset but lacks the general knowledge encoded in the Google News model.\n",
    "<br><br>\n",
    "<h3>Question b</h3>\n",
    "The Google News model encodes semantic relationships more effectively in a general sense. Its ability to correctly map “Doctor - Hospital + Court” = “judge” implies that it has learned real-world relations between professions and locations.<br>\n",
    "\n",
    "However, the custom model performs better in domain-specific contexts. The higher similarity score for “happy” and “satisfied” suggests that it effectively handles sentiment-related words used in customer reviews.\n",
    "<br>\n",
    "In conclusion, if the goal is general-purpose word understanding, the Google News model is superior. But for sentiment analysis within Amazon reviews, the custom model may be more useful as it learns contextually relevant relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing from HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contract_dict = {\n",
    "    \"he'll\": \"he will\",\"he'll've\": \"he will have\",\"isn't\": \"is not\",\"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\"it'll\": \"it will\",\"it'll've\": \"it will have\",\"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\"mightn't\": \"might not\",\"might've\": \"might have\",\n",
    "    \"must've\": \"must have\",\"mustn't\": \"must not\",\"needn't\": \"need not\",\"ain't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\"can't\": \"cannot\",\"couldn't\": \"could not\",\"could've\": \"could have\",\n",
    "    \"couldn't've\": \"could not have\",\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\"hasn't\": \"has not\",\"haven't\": \"have not\",\n",
    "    \"haven't've\": \"have not have\",\"he'd\": \"he would\",\"he'd've\": \"he would have\",\"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\"shalln't\": \"shall not\",\"shan't\": \"shall not\",\"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\"he's\": \"he is\",\"how'd\": \"how did\",\"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\"how's\": \"how is\",\"I'd\": \"I would\",\"I'd've\": \"I would have\",\n",
    "    \"I'll\": \"I will\",\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\"I'd\": \"I had\",\n",
    "    \"I'd've\": \"I had have\",\"I'm\": \"I am\",\"I've\": \"I have\",\"she'll\": \"she will\",\"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\"should've\": \"should have\",\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\"so's\": \"so is\",\"that'd\": \"that would\",\"that'd've\": \"that would have\",\"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\"there'd've\": \"there would have\",\"there's\": \"there is\",\"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\"weren't\": \"were not\",\n",
    "    \"what'd\": \"what did\",\"what'd'y\": \"what do you\",\"what'll\": \"what will\",\"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\"what's\": \"what is\",\"where've\": \"where have\",\"who'd\": \"who would\",\n",
    "    \"who'd've\": \"who would have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\"why'd\": \"why did\",\"why'll\": \"why will\",\"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\"you'd\": \"you would\",\"you'd've\": \"you would have\",\"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\"you're\": \"you are\",\"you've\": \"you have\",\"what've\": \"what have\",\n",
    "    \"when'd\": \"when did\",\"when'll\": \"when will\",\"when's\": \"when is\",\"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\"where'll\": \"where will\",\"where's\": \"where is\",\n",
    "}\n",
    "\n",
    "def review_cleaning(review):\n",
    "    review = review.lower()\n",
    "    if \"<\" in review and \">\" in review: \n",
    "        review = BeautifulSoup(review, \"html.parser\").get_text()\n",
    "    review = re.sub(r'http\\S+|www\\S+', '', review)\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in contract_dict.keys()) + r')\\b')\n",
    "    review = pattern.sub(lambda x: contract_dict[x.group()], review)\n",
    "    review = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "    review = re.sub(r'\\s+', ' ', review).strip()\n",
    "    return review\n",
    "\n",
    "balanced_df['review_body'] = balanced_df['review_body'].astype(str)\n",
    "balanced_df['review_body'] = balanced_df['review_body'].apply(review_cleaning)\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def stopwords_removal(review):\n",
    "    words = review.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    review = ' '.join(words)\n",
    "    return review\n",
    "\n",
    "balanced_df['review_body'] = balanced_df['review_body'].apply(stopwords_removal)\n",
    "\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def review_lemmatization(review):\n",
    "    words = review.split()\n",
    "    words = [lemma.lemmatize(word) for word in words]\n",
    "    review = ' '.join(words)\n",
    "    return review\n",
    "\n",
    "\n",
    "\n",
    "balanced_df['review_body'] = balanced_df['review_body'].apply(review_lemmatization)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created another dataframe binary_df to use this for binary classification by removing the neutral class(sentiment=3) rows from the balanced_df( which contains all the classes).<br>\n",
    "Also, the tokenized version of the training and testing data are stored separately for future use in the following sections of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_df = balanced_df[balanced_df['sentiment'] != 3]\n",
    "\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(binary_df['review_body'], binary_df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_token = [word_tokenize(text) for text in X_train_bin]\n",
    "X_test_token = [word_tokenize(text) for text in X_test_bin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using each feature extraction method(TF-IDF, pretrained model, custom model), I trained and evaluated two classification models(Perceptron and SVM).<br>\n",
    "TF-IDF vectors were generated using TfidfVectorizer().<br>\n",
    "Word2Vec feature vectors were computed by averaging the word embeddings of all tokens in each review in the avg_vector function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_idf = TfidfVectorizer()\n",
    "tf_idf.fit(binary_df['review_body'])\n",
    "X_train_tfidf = tf_idf.transform(X_train_bin)\n",
    "X_test_tfidf = tf_idf.transform(X_test_bin)     \n",
    "\n",
    "def avg_vector(review, model, vector_size=300):\n",
    "    vectors = [model[word] for word in review if word in model]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(vector_size)  \n",
    "\n",
    "\n",
    "X_train_bin_avg_pre = np.array([avg_vector(review, pre_model) for review in X_train_token])\n",
    "X_test_bin_avg_pre = np.array([avg_vector(review, pre_model) for review in X_test_token])\n",
    "\n",
    "X_train_bin_avg_cus = np.array([avg_vector(review, custom_mod.wv) for review in X_train_token])\n",
    "X_test_bin_avg_cus = np.array([avg_vector(review, custom_mod.wv) for review in X_test_token])\n",
    "\n",
    "def train_eval(X_train, X_test, y_train, y_test, f_type):\n",
    "\n",
    "    perceptron = Perceptron(max_iter=1000,eta0=0.01, random_state=42)\n",
    "    perceptron.fit(X_train, y_train)\n",
    "    y_pred_perceptron = perceptron.predict(X_test)\n",
    "    perceptron_acc = accuracy_score(y_test, y_pred_perceptron)\n",
    " \n",
    "    svm = LinearSVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred_svm = svm.predict(X_test)\n",
    "    svm_acc = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "    print(f\"Feature: {f_type}\")\n",
    "    print(f\"Perceptron Accuracy: {perceptron_acc:.4f}\")\n",
    "    print(f\"SVM Accuracy: {svm_acc:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: TF-IDF\n",
      "Perceptron Accuracy: 0.8150\n",
      "SVM Accuracy: 0.8637\n",
      "\n",
      "Feature: Word2Vec-Google-News-300\n",
      "Perceptron Accuracy: 0.7544\n",
      "SVM Accuracy: 0.8161\n",
      "\n",
      "Feature: Custom Word2Vec\n",
      "Perceptron Accuracy: 0.7825\n",
      "SVM Accuracy: 0.8435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_eval(X_train_tfidf, X_test_tfidf, y_train_bin, y_test_bin, \"TF-IDF\")\n",
    "train_eval(X_train_bin_avg_pre, X_test_bin_avg_pre, y_train_bin, y_test_bin, \"Word2Vec-Google-News-300\")\n",
    "train_eval(X_train_bin_avg_cus, X_test_bin_avg_cus, y_train_bin, y_test_bin, \"Custom Word2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, we observe the following performance differences across the three feature extraction methods:\n",
    "\n",
    "<table border=\"1\">\n",
    "    <tr>\n",
    "        <th>Feature Type</th>\n",
    "        <th>Perceptron Accuracy</th>\n",
    "        <th>SVM Accuracy</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>TF-IDF</b></td>\n",
    "        <td>0.8150</td>\n",
    "        <td>0.8637</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Google Word2Vec</b></td>\n",
    "        <td>0.7544</td>\n",
    "        <td>0.8161</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Custom Word2Vec</b></td>\n",
    "        <td>0.7825</td>\n",
    "        <td>0.8435</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion from comparing performances for the models trained using the three different feature types (TF-IDF, pretrainedWord2Vec, custom Word2Vec)\n",
    "TF-IDF outperforms both Word2Vec models<br>\n",
    "•Highest accuracy (Perceptron: 0.8150, SVM: 0.8637)<br>\n",
    "•Since TF-IDF is purely frequency-based, it effectively captures important terms in the dataset without relying on word meanings. This suggests that sentiment classification in this dataset benefits more from word importance rather than contextual meaning.\n",
    "<br> <br>\n",
    "Custom Word2Vec performs better than Google Word2Vec in Perceptron<br>\n",
    "•Perceptron with Custom Word2Vec (0.7825) is higher than Perceptron with Google Word2Vec (0.7544).<br>\n",
    "•This might produce different results as we change random_state. Sometimes, the pretrained model may produce better results on perceptron.<br><br>\n",
    "\n",
    "Custom Word2Vec performs better than Google Word2Vec with SVM<br>\n",
    "•SVM with Custom Word2Vec (0.8435) is higher than SVM with Google Word2Vec (0.8161).<br>\n",
    "•This indicates that domain-specific embeddings (Custom Word2Vec) are more effective than general-purpose embeddings (Google Word2Vec) for sentiment classification in Amazon reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the GPU of mac, MPS for accelaration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implements and trains a Multi-Layer Perceptron (MLP) to classify sentiment using different feature representations. The neural network consists of three fully connected layers with ReLU activation. The model is trained using Cross-Entropy Loss and optimized with Adam. <br><br>\n",
    "The network consists of:<br>\n",
    "•\tInput layer → Fully connected (linear) layer with 50 neurons <br>\n",
    "•\tHidden layer → Fully connected layer with 10 neurons    <br>\n",
    "•\tOutput layer → Fully connected layer matching the number of output classes <br><br>\n",
    "ReLU activation is used in the first two layers to introduce non-linearity. <br><br>\n",
    "In the train_mlp function, an MLP instance is created based on the input and output sizes. The model is trained for 10 epochs using mini-batches (batch size = 32) from the DataLoader.<br><br>\n",
    "The prep_tensors function converts input features into PyTorch tensors. Also, I am shifting labels in this function to have zero-based indexing which is needed for classification. Since, our labels are {1, 2, 3}, it is changed to {0, 1, 2}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        self.fc3 = nn.Linear(10, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return self.fc3(x)  \n",
    "\n",
    "def train_mlp(X_train, y_train, X_test, y_test, input_size, output_size, model_name):\n",
    "    mod = MLP(input_size, output_size).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(mod.parameters(), lr=0.001)\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = mod(batch_X)\n",
    "            loss = loss_fn(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_outputs = mod(X_test)\n",
    "        predictions = torch.argmax(test_outputs, dim=1)\n",
    "        accuracy = (predictions == y_test).float().mean().item()\n",
    "    \n",
    "    print(f\"{model_name}: {accuracy:.4f}\")\n",
    "\n",
    "def prep_tensors(X, y, shift_labels=True):\n",
    "    y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
    "    if shift_labels:  \n",
    "        y_tensor -= 1  \n",
    "    return torch.tensor(X, dtype=torch.float32).to(device), y_tensor.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep for ternary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to data preparation of the binary classification, here I am splitting data for ternary classification which is stored in balanced_df. Again, I have stored the tokenized version of the review_body separately. I have applied the avg_vector function to get the average Word2Vec features for ternary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ter, X_test_ter, y_train_ter, y_test_ter = train_test_split(balanced_df['review_body'], balanced_df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_ter_token = [word_tokenize(text) for text in X_train_ter]\n",
    "X_test_ter_token = [word_tokenize(text) for text in X_test_ter]\n",
    "\n",
    "X_train_ter_avg_pre = np.array([avg_vector(review, pre_model) for review in X_train_ter_token])\n",
    "X_test_ter_avg_pre = np.array([avg_vector(review, pre_model) for review in X_test_ter_token])\n",
    "\n",
    "X_train_ter_avg_cus = np.array([avg_vector(review, custom_mod.wv) for review in X_train_ter_token])\n",
    "X_test_ter_avg_cus = np.array([avg_vector(review, custom_mod.wv) for review in X_test_ter_token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average w2v (part a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I am converting the input average w2v features into Pytorch tensors using the prep_tensor function. So the tensors for both custom and pretrained model for binary and ternary classification are obtained here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AVG custom-binary\n",
    "X_train_avg_bin_tensor, y_train_bin_tensor = prep_tensors(X_train_bin_avg_cus, y_train_bin)\n",
    "X_test_avg_bin_tensor, y_test_bin_tensor = prep_tensors(X_test_bin_avg_cus, y_test_bin)\n",
    "\n",
    "#AVG pretrained-binary\n",
    "X_train_avg_google_tensor, y_train_google_tensor = prep_tensors(X_train_bin_avg_pre, y_train_bin)\n",
    "X_test_avg_google_tensor, y_test_google_tensor = prep_tensors(X_test_bin_avg_pre, y_test_bin)\n",
    "\n",
    "#AVG custom-ternary\n",
    "X_train_avg_ter_tensor, y_train_ter_tensor = prep_tensors(X_train_ter_avg_cus, y_train_ter)\n",
    "X_test_avg_ter_tensor, y_test_ter_tensor = prep_tensors(X_test_ter_avg_cus, y_test_ter)\n",
    "\n",
    "#AVG pretrained-ternary\n",
    "X_train_avg_google_ter_tensor, y_train_google_ter_tensor = prep_tensors(X_train_ter_avg_pre, y_train_ter)\n",
    "X_test_avg_google_ter_tensor, y_test_google_ter_tensor = prep_tensors(X_test_ter_avg_pre, y_test_ter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary - Avg W2V (Google): 0.8434\n"
     ]
    }
   ],
   "source": [
    "train_mlp(X_train_avg_google_tensor, y_train_google_tensor, X_test_avg_google_tensor, y_test_google_tensor, 300, 2, \"Binary - Avg W2V (Google)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary - Avg Custom W2V: 0.8625\n"
     ]
    }
   ],
   "source": [
    "train_mlp(X_train_avg_bin_tensor, y_train_bin_tensor, X_test_avg_bin_tensor, y_test_bin_tensor, 300, 2, \"Binary - Avg Custom W2V\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ternary - Avg W2V (Google): 0.6860\n"
     ]
    }
   ],
   "source": [
    "train_mlp(X_train_avg_google_ter_tensor, y_train_google_ter_tensor, X_test_avg_google_ter_tensor, y_test_google_ter_tensor, 300, 3, \"Ternary - Avg W2V (Google)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ternary - Avg Custom W2V: 0.7031\n"
     ]
    }
   ],
   "source": [
    "train_mlp(X_train_avg_ter_tensor, y_train_ter_tensor, X_test_avg_ter_tensor, y_test_ter_tensor, 300, 3, \"Ternary - Avg Custom W2V\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the accuracy values using the average Word2Vec\n",
    "<table border=\"1\">\n",
    "    <tr>\n",
    "        <th>Classification Type</th>\n",
    "        <th>Feature Representation</th>\n",
    "        <th>Accuracy</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Binary</td>\n",
    "        <td>Avg W2V (Google)</td>\n",
    "        <td>0.8434</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Binary</td>\n",
    "        <td>Avg Custom W2V</td>\n",
    "        <td>0.8625</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Ternary</td>\n",
    "        <td>Avg W2V (Google)</td>\n",
    "        <td>0.6860</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Ternary</td>\n",
    "        <td>Avg Custom W2V</td>\n",
    "        <td>0.7031</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenated w2v (part b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I am concatenating the first 10 Word2Vec vectors for each review as the input feature using the concat_vector function.<br>\n",
    "This function is applied to train and test tokens of both binary and ternary data. Later, the tensors are obtained similar to the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_vector(review, model, vector_size=300, max_words=10):\n",
    "    vectors = [model[word] for word in review if word in model][:max_words]  \n",
    "    while len(vectors) < max_words:  \n",
    "        vectors.append(np.zeros(vector_size))\n",
    "    return np.concatenate(vectors)\n",
    "\n",
    "X_train_bin_concat_pre = np.array([concat_vector(review, pre_model) for review in X_train_token])\n",
    "X_test_bin_concat_pre = np.array([concat_vector(review, pre_model) for review in X_test_token])\n",
    "\n",
    "X_train_bin_concat_cus = np.array([concat_vector(review, custom_mod.wv) for review in X_train_token])\n",
    "X_test_bin_concat_cus = np.array([concat_vector(review, custom_mod.wv) for review in X_test_token])\n",
    "\n",
    "X_train_ter_concat_pre = np.array([concat_vector(review, pre_model) for review in X_train_ter_token])\n",
    "X_test_ter_concat_pre = np.array([concat_vector(review, pre_model) for review in X_test_ter_token])\n",
    "\n",
    "X_train_ter_concat_cus = np.array([concat_vector(review, custom_mod.wv) for review in X_train_ter_token])\n",
    "X_test_ter_concat_cus = np.array([concat_vector(review, custom_mod.wv) for review in X_test_ter_token])\n",
    "\n",
    "#CONCAT custom-binary\n",
    "X_train_concat_bin_tensor, y_train_bin_tensor = prep_tensors(X_train_bin_concat_cus, y_train_bin)\n",
    "X_test_concat_bin_tensor, y_test_bin_tensor = prep_tensors(X_test_bin_concat_cus, y_test_bin)\n",
    "\n",
    "#CONCAT pretrained-binary\n",
    "X_train_concat_google_tensor, y_train_google_tensor = prep_tensors(X_train_bin_concat_pre, y_train_bin)\n",
    "X_test_concat_google_tensor, y_test_google_tensor = prep_tensors(X_test_bin_concat_pre, y_test_bin)\n",
    "\n",
    "#CONCAT custom-ternary\n",
    "X_train_concat_ter_tensor, y_train_ter_tensor = prep_tensors(X_train_ter_concat_cus, y_train_ter)\n",
    "X_test_concat_ter_tensor, y_test_ter_tensor = prep_tensors(X_test_ter_concat_cus, y_test_ter)\n",
    "\n",
    "#CONCAT pretrained-ternary\n",
    "X_train_concat_google_ter_tensor, y_train_google_ter_tensor = prep_tensors(X_train_ter_concat_pre, y_train_ter)\n",
    "X_test_concat_google_ter_tensor, y_test_google_ter_tensor = prep_tensors(X_test_ter_concat_pre, y_test_ter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary - concat W2V (Google): 0.7531\n"
     ]
    }
   ],
   "source": [
    "train_mlp(X_train_concat_google_tensor, y_train_google_tensor, X_test_concat_google_tensor, y_test_google_tensor, 3000, 2, \"Binary - concat W2V (Google)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary - concat Custom W2V: 0.7735\n"
     ]
    }
   ],
   "source": [
    "train_mlp(X_train_concat_bin_tensor, y_train_bin_tensor, X_test_concat_bin_tensor, y_test_bin_tensor, 3000, 2, \"Binary - concat Custom W2V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ternary - concat W2V (Google): 0.5983\n"
     ]
    }
   ],
   "source": [
    "train_mlp(X_train_concat_google_ter_tensor, y_train_google_ter_tensor, X_test_concat_google_ter_tensor, y_test_google_ter_tensor, 3000, 3, \"Ternary - concat W2V (Google)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ternary - concat Custom W2V: 0.6183\n"
     ]
    }
   ],
   "source": [
    "train_mlp(X_train_concat_ter_tensor, y_train_ter_tensor, X_test_concat_ter_tensor, y_test_ter_tensor, 3000, 3, \"Ternary - concat Custom W2V\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the accuracy values using the concatenated Word2Vec\n",
    "<table border=\"1\">\n",
    "    <tr>\n",
    "        <th>Classification Type</th>\n",
    "        <th>Feature Representation</th>\n",
    "        <th>Accuracy</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Binary</td>\n",
    "        <td>Concat W2V (Google)</td>\n",
    "        <td>0.7560</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Binary</td>\n",
    "        <td>Concat Custom W2V</td>\n",
    "        <td>0.7735</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Ternary</td>\n",
    "        <td>Concat W2V (Google)</td>\n",
    "        <td>0.5903</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Ternary</td>\n",
    "        <td>Concat Custom W2V</td>\n",
    "        <td>0.6176</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Feedforward Neural Network (FNN) with Average Word2Vec performs better than Simple Models:<br>\n",
    "•Binary - Avg Custom W2V (0.86225) achieves nearly the same accuracy as SVM with TF-IDF (0.8637), making it a strong alternative.<br>\n",
    "•Binary - Avg W2V (Google) (0.8434) outperforms both SVM with Google Word2Vec (0.8161) and SVM with Custom Word2Vec (0.8435).<br><br>\n",
    "\n",
    "FNN with Concatenated Word2Vec performs worse than Simple Models:<br>\n",
    "•Binary - concat Custom W2V (0.7735) and Binary - concat W2V (Google) (0.7560) have lower accuracy than all simple models.<br>\n",
    "•This suggests that averaging word embeddings is a better feature representation than concatenation for sentiment classification.<br><br>\n",
    "\n",
    "Ternary - Avg Custom W2V (0.7031) and Ternary - Avg W2V (Google) (0.6860) show a noticeable drop in accuracy compared to binary classification.<br>\n",
    "Ternary - concat Custom W2V (0.6176) and Ternary - concat W2V (Google) (0.5903) perform the worst, reinforcing that concatenation is less effective.<br><br>\n",
    "\n",
    "Overall, FNN with average embeddings is competitive with SVM models, particularly for binary classification. TF-IDF remains the strongest feature extraction method overall. Ternary classification struggles across all methods, showing that distinguishing three sentiment classes is much harder than binary classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w2c_embedding function generates word embeddings for a given tokenized review using a Word2Vec model. It returns a (50 × 300) matrix, where each row represents a word vector. To maintain consistency in input size, all reviews are padded or truncated to a fixed length of 50 words.<br><br>\n",
    "\n",
    "The SADataset class is designed to store and provide access to tokenized reviews and their corresponding labels in a format compatible with PyTorch’s DataLoader. It accepts tokenized review text, sentiment labels(zero-based index), and a Word2Vec model. <br>\n",
    "I used __ getitem __ method retrieves the precomputed (50 × 300) embedding matrix for each review and its corresponding label.<br><br>\n",
    "\n",
    "After that, the dataset is prepared for both binary and ternary classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Word2Vec embeddings\n",
    "def w2c_embedding(tokens, model, max_len=50, vector_size=300):\n",
    "    f_vectors = [model[word] if word in model else np.zeros(vector_size, dtype=np.float32) for word in tokens]\n",
    "    if len(f_vectors) < max_len:\n",
    "        f_vectors.extend([np.zeros(vector_size, dtype=np.float32)] * (max_len - len(f_vectors)))\n",
    "    return np.array(f_vectors[:max_len], dtype=np.float32) \n",
    "\n",
    "# PyTorch Dataset Class\n",
    "class SADataset(Dataset):\n",
    "    def __init__(self, review_tokens, labels, model):\n",
    "        self.review_tokens = review_tokens  \n",
    "        self.labels = [label - 1 for label in labels]  # zero based indexing\n",
    "        self.model = model.wv if hasattr(model, \"wv\") else model  # Word2Vec Model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.review_tokens[idx] \n",
    "        embedding = w2c_embedding(tokens, self.model) \n",
    "        label = self.labels[idx]  \n",
    "        return torch.tensor(embedding, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "train_bin_pre = SADataset(X_train_token, y_train_bin, pre_model)\n",
    "test_bin_pre = SADataset(X_test_token, y_test_bin, pre_model)\n",
    "train_bin_cus = SADataset(X_train_token, y_train_bin, custom_mod.wv)\n",
    "test_bin_cus = SADataset(X_test_token, y_test_bin, custom_mod.wv)\n",
    "train_ter_pre = SADataset(X_train_ter_token, y_train_ter, pre_model)\n",
    "test_ter_pre = SADataset(X_test_ter_token, y_test_ter, pre_model)\n",
    "train_ter_cus = SADataset(X_train_ter_token, y_train_ter, custom_mod.wv)\n",
    "test_ter_cus = SADataset(X_test_ter_token, y_test_ter, custom_mod.wv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN model is designed to process word embedding matrices of size (50 × 300), where each review is represented as a sequence of 50 words, with each word embedded into a 300-dimensional vector.<br>\n",
    "Kernel size = 3<br>\n",
    "I used ReLU function for activation.<br>\n",
    "The input and output size for the first layer are 300 and 50 channels respectively.<br>\n",
    "The input and output size for the second layer are 50 and 10 channels respectively.<br>\n",
    "The output of the second convolutional layer is flattened and fed into a fully connected layer with output neurons equal to the number of classes (binary: 2, ternary: 3).<br>\n",
    "I used _get_conv_output function to compute the output size of the convolutional layers dynamically, ensuring compatibility with varying input lengths.<br><br>\n",
    "\n",
    "After this, train_cnn function trains the CNN model using CrossEntropyLoss and the Adam optimizer. The model is trained for a default of 10 epochs with a learning rate of 0.001. The model iterates through mini-batches from the training set.<br>\n",
    "After training, the model is set to evaluation mode (model.eval()). The accuracy is calculated on the test set by comparing predicted and actual labels.<br><br>\n",
    "The datasets are wrapped in PyTorch’s DataLoader to facilitate efficient batch processing. I have set the batch size to 64 and also I have enabled shuffling to enhance model generalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels=300, op_size=3):  # 3 classes for ternary \n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=50, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=50, out_channels=10, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        sam_ip = torch.zeros(1, input_channels, 50)  \n",
    "        sam_op = self._get_conv_output(sam_ip)\n",
    "        self.fc1 = nn.Linear(sam_op, op_size)  \n",
    "\n",
    "    def _get_conv_output(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        return x.view(x.shape[0], -1).shape[1]  # Flatten size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  #(batch, channel, sequence)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)  # Flatten before fc1\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "#Train CNN Model with DataLoader \n",
    "def train_cnn(train_loader, test_loader, num_classes, epochs=10, lr=0.001):\n",
    "    model = CNN(op_size=num_classes).to(device)  \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)  \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)  \n",
    "            loss = loss_fn(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)  \n",
    "            outputs = model(batch_X)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"{accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "# Dataloaders for binary and ternary classification\n",
    "train_bin_cus_loader = DataLoader(train_bin_cus, batch_size=64, shuffle=True)\n",
    "test_bin_cus_loader = DataLoader(test_bin_cus, batch_size=64, shuffle=False)\n",
    "train_bin_pre_loader = DataLoader(train_bin_pre, batch_size=64, shuffle=True)\n",
    "test_bin_pre_loader = DataLoader(test_bin_pre, batch_size=64, shuffle=False)\n",
    "train_ter_cus_loader = DataLoader(train_ter_cus, batch_size=64, shuffle=True)\n",
    "test_ter_cus_loader = DataLoader(test_ter_cus, batch_size=64, shuffle=False)\n",
    "train_ter_pre_loader = DataLoader(train_ter_pre, batch_size=64, shuffle=True)\n",
    "test_ter_pre_loader = DataLoader(test_ter_pre, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN for Binary Classification\n",
      "\n",
      "Accuracy(pretrained model with CNN): \n",
      "0.8610\n",
      "\n",
      "Accuracy(custom model with CNN):\n",
      "0.8642\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining CNN for Binary Classification\")\n",
    "print(\"\\nAccuracy(pretrained model with CNN): \")\n",
    "accuracy_cnn_bin_pre = train_cnn(train_bin_pre_loader, test_bin_pre_loader, num_classes=2)\n",
    "print(\"\\nAccuracy(custom model with CNN):\")\n",
    "accuracy_cnn_bin_cus = train_cnn(train_bin_cus_loader, test_bin_cus_loader, num_classes=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN for Ternary Classification\n",
      "\n",
      "Accuracy(pretrained model with CNN):\n",
      "0.7005\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining CNN for Ternary Classification\")\n",
    "print(\"\\nAccuracy(pretrained model with CNN):\")\n",
    "accuracy_cnn_tern_pre = train_cnn(train_ter_pre_loader, test_ter_pre_loader, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy(custom model with CNN):\n",
      "0.7069\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAccuracy(custom model with CNN):\")\n",
    "accuracy_cnn_tern_cus = train_cnn(train_ter_cus_loader, test_ter_cus_loader, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the accuracy values on the testing split of binary and ternary data using CNN:\n",
    "<table border=\"1\">\n",
    "    <tr>\n",
    "        <th>Model</th>\n",
    "        <th>Pretrained Word2Vec</th>\n",
    "        <th>Custom Word2Vec</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Binary Classification</th>\n",
    "        <td>0.8610</td>\n",
    "        <td>0.8642</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Ternary Classification</th>\n",
    "        <td>0.7005</td>\n",
    "        <td>0.7069</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
